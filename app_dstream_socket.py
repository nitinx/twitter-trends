# Design Pattern | Spark DStream | Socket
# Count words received via a network socket
# To Execute: spark-submit dstream_socket.py

import sys
import sched, time
from pyspark import SparkContext
from pyspark.streaming import StreamingContext

if __name__ == "__main__":

    # Initialize Spark Context Objects
    sc = SparkContext(appName='SparkStreaming')
    ssc = StreamingContext(sc, 10)
    
    # Create Checkpoint
    ssc.checkpoint("file:///tmp/spark")
    
    # Function | Word Count
    def countWords(newValues, lastSum):
        if lastSum is None:
            lastSum = 0
        return sum(newValues, lastSum)
    
    # Initialize Stream Object
    lines = ssc.socketTextStream("localhost", 7777)
        
    # Parse Stream Data
    word_count = lines.flatMap(lambda line: line.split(" ")).filter(lambda w: w.startswith("#")).map(lambda word: (word, 1)).updateStateByKey(countWords)
    
    # Print first ten elements of each DStream RDD
    word_count.pprint(num=10)    
    
    # Start Process
    ssc.start()
    
    #s = sched.scheduler(time.time, time.sleep)
    #s.enter(10, 1, print_details, (s))
    #s.run()
    
    # Wait for Process Termination
    ssc.awaitTermination()
